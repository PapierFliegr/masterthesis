\chapter{Disconnected Minimizer}
\label{ch:disconnected_minimizer}

When discussing the connectedness of the model in \Cref{ch:models} in the case that \( R < 2 \), we
first just stated, that if \( R < 2 \) then at least the cylinder \( Z_R \coloneqq B^\prime_{R/2}
\times (- M, M) \) is in the minimizer. This fact is not enough for connectedness of the minimizer.
To show connectedness, we would still need to show, that there cannot exist a part of the minimizer
that is fully detached from the cylinder and the external data. \\

Motivated by the fact, that in the classical case, if we have some external data \( E_0 \) and some
prescribed set \( \Omega \) that are fully disconnected, i.e.\ \( \dist(E_0, \Omega) \eqqcolon d > 0
\), then the minimizer is the external data itself, we wanted to prove the same thing for the
nonlocal case as well. \\

Indeed, if we could show that, then the existence of the cylinder \( Z_R \) is enough to conclude
that the minimizer is connected. Assume there exists a part of the minimizer that is not connected
to the cylinder and the external data, i.e.\ there exists a set \( E_1 \) such that \( \dist(E_1,
E_0 \cup A) > 0 \) with \( A\coloneqq E_M \setminus (E_0 \cup E_1) \). We can assume that \( A \) is
connected and notice that \( Z_R \subset A \). Then we can rewrite the fractional perimeter of \(
E_M \coloneqq E_0 \cup A \cup E_1 \) relative to \( \Omega \) as follows:
\begin{align*}
	\Per{s}{E_M}{\Omega}
	 & = \L(E_M \cap \Omega, E_M^c) + \L(E_M \setminus \Omega, \Omega \setminus E_M) \\
	 & = \L(E_1 \cup A, E_M^c) + \L(E_0, \Omega \setminus (E_1 \cup A)) \\
	 & = \L(E_1, E_M^c) + \L(A, E_M^c) + \L(E_0 \cup A, \Omega \setminus (E_1 \cup A)) - \L(A, \Omega \setminus (E_1 \cup A)) \\
	 & = \Per{s}{E_M}{\Omega \setminus A} + \L(A, {(E_0 \cup A)}^c).
	\tagged\label{eq:201}
\end{align*}
Notice that the second term in \Cref{eq:201} is now independent of \( E_1 \), thus to minimize \(
\Per{s}{E_M}{\Omega} \) we can first minimize \( \L(A, {(E_0 \cup A)}^c) \) over \( A \) and then
minimize \( \Per{s}{E_M}{\Omega \setminus A} \). \\

We define a sequence of prescribed sets \( {(\Omega_n)}_n \) such that \( \Omega_n \subset \Omega_{n
	+ 1} \subset \Omega \) and \( \dist(E_0 \cup A, \Omega_n) = \frac{d}{n} \), where \( d \coloneqq
\dist(E_0 \cup A, E_1) \). Then for each \( n \) we are in the situation of fully disconnected
external data, here \( E_0 \cup A \), and prescribed set, here \( \Omega_n \). If our assumption,
that nonlocal minimizers behave like the classical minimizers for disconnected external data and
prescribed set, is correct, then we could conclude
\begin{gather*}
	\Per{s}{E_M}{\Omega \setminus A} \geq \Per{s}{E_M}{\Omega_n} \geq \Per{s}{E_0}{\Omega_n} \nearrow \Per{s}{E_0}{\Omega \setminus A}.
\end{gather*}
That is, if there exists a set \( E_1 \) fully detached from \( E_0 \cup A \), then its fractional
perimeter relative to \( \Omega \) is larger than the fractional perimeter of \( E_0 \cup A \)
relative to \( \Omega \). Thus, there couldn't exist a set \( E_1 \) fully detached from \( E_0 \cup
Z_R \). \\

As it turns out, this is \emph{not} true in general, and thus we cannot state connectedness just with the
existence of the cylinder in the minimizer.\\

In the following, we will consider an example of a model where the external data and the prescribed
set have nonzero distance, but the minimizer is not the external data itself. We will then generalize
the example to arbitrary dimensions \( n \geq 2 \) and radii.
\begin{example}
	\label{ex:201}
	Let \( E_0 = B_2^c \) and \( \Omega = B_1 \) in \( \mathbb{R}^2 \). Then we compare the fractional
	perimeter of \( E_0 \) relative to \( \Omega \) with the fractional perimeter of \( E_0 \cup
	\Omega \) relative to \( \Omega \), that is
	\begin{gather*}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega} = \Per{s}{B_1}{} - 2L(B_2^c, B_1), \tagged\label{eq:208}
	\end{gather*}
	and show that this difference is negative for \( s \) small enough. If the difference is negative
	we have found a competitor to the external data with smaller fractional perimeter and thus the
	external data cannot be the minimizer. \\

	For the first term we have by~\cite[Eq. (11)]{haddad2022affine}
	\begin{gather*}
		\Per{s}{B_1}{} = \frac{2^{2 - s} \pi^{\frac{3}{2}}}{s(2 - s)} \frac{\Gamma(\frac{1 - s}{2})}{\Gamma(\frac{2 - s}{2})}.
	\end{gather*}

	We want to bound the second term from above and below. For that we will split the domain depending
	on \( x \), see \Cref{fig:201}.

	\begin{figure}[ht]
		\centering
		\def\svgscale{1}
		\import{figures/split_domain}{split_domain.pdf_tex}
		\caption{Splitting of \( B_2^c \) depending on \( x \).}
		\label{fig:201}
	\end{figure}

	Thus, we have
	\begin{gather*}
		\L(B_2^c, B_1) = \int_{B_1} \int_{B_2^c} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{y} \dd{x}
		= \underbrace{\int_{B_1} \int_{B_{2 + \lvert x \rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{y} \dd{x}}_{I_1} + \underbrace{\int_{B_1} \int_{B_{2 + \lvert x \rvert}(x)\setminus B_2} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{y} \dd{x}}_{I_2}.
	\end{gather*}
	We start with \( I_1 \):
	\begin{align*}
		I_1
		 & = \int_{B_1} \int_{B_{2 + \lvert x\rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2 + s}} \dd{y} \dd{x}
		= \int_{B_1} \int_{B_{2 + \lvert x\rvert}^c} \frac{1}{\lvert y \rvert^{2 + s}} \dd{y} \dd{x} \\
		 & = 4 \pi^2 \int_0^1 \int_{2 + r_1}^\infty \frac{r_1}{r_2^{1 + s}} \dd{r_2} \dd{r_1}
		= \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{{(2 + r_1)}^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1 - s)(2 - s)} \left(2^{2 - s} - (s + 1) 3^{1 - s} \right).
	\end{align*}

	Now to \( I_2 \). Here the idea is to use radial coordinates again. Since the integral is radial
	symmetric w.r.t.\ \( x \), we can fix \( x \) such that \( x = (r, 0) \) for \( r = \lvert x\rvert
	\). Now for fixed \( x \) the domain of \( y \) is not radial symmetric, thus we first have to
	compute the domain of \( \vartheta \coloneqq \vartheta (r_1, r_2) \). \\
	We have two restrictions on \( y \):

	\begin{enumerate}[label = (\arabic*)]
		\item \( 4 \leq \lvert x - y\rvert^2 \leq {(2 + 2\lvert x\rvert)}^2 \)
		\item \( 2 - \lvert x\rvert \leq \lvert y\rvert \leq 2 + \lvert x\rvert \)
	\end{enumerate}

	From the first restriction with \( \lvert x\rvert = r_1 \), \( \lvert y\rvert = r_2 \) and \(
	\vartheta \) the angle between \( x \) and \( y \) we get
	\begin{alignat*}{3}
    && 4 &\leq{}& \centermath{\lvert x - y\rvert^2} & \leq {(2 + 2r_1)}^2 \\
    \Leftrightarrow\ && 4 &\leq{}& \centermath{r_1^2 + r_2^2 - 2r_1 r_2 \cos(\vartheta)} & \leq 4{(1 + r_1)}^2 \\
    \Leftrightarrow\ && \frac{r_1^2 + r_2^2 - 4}{2r_1 r_2} &\geq{}& \centermath{\cos(\vartheta)} & \geq \frac{r_1^2 + r_2^2 - 4{(1 + r_1)}^2}{2r_1 r_2}.  \tagged\label{eq:207}
  \end{alignat*}
	From the second restriction we have that the right-hand side of \Cref{eq:207} is always greater or
	equal to \( - 1 \), thus we have
	\begin{gather*}
		\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2} \geq \cos(\vartheta) \geq - 1.
	\end{gather*}
	We will see, that for all \( r_1 \) and \( r_2 \) the argument of \( I_2 \) is independent of \( \vartheta \),
	thus we can integrate over \( \vartheta \) first with \( \vartheta \in D_\vartheta \coloneqq \left(0,
	\arccos\left(\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2}\right)\right) \cup \left(2 \pi - \arccos\left(\frac{r_1^2 +
			r_2^2 - 4}{2r_1 r_2}\right), 2 \pi\right) \)
	\begin{gather*}
		\int_{D_\vartheta} \dd{\vartheta} = 2\pi - 2 \arccos\left(\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2}\right).
	\end{gather*}

	For \( I_2 \) we can follow
	\begin{align*}
		I_2
		 & = \int_{B_1} \int_{B_{2 + \lvert x\rvert} (x) \setminus B_2} \frac{1}{\lvert x - y \rvert^{2 + s}} \dd{y} \dd{x}
		= \int_{B_1} \underbrace{\int_{B_{2 + \lvert x \rvert} \setminus B_2(- x)} \frac{1}{\lvert y \rvert^{2 + s}} \dd{y}}_{\text{radial symmetric w.r.t.\ \( x \)}} \dd{x}.
		\intertext{We use radial coordinates}
		 & = 2 \pi \int_0^1 \int_{2 - r_1}^{2 + r_1} \frac{r_1}{r_2^{1 + s}} \int_{- \vartheta}^\vartheta \dd{\vartheta} \dd{r_2} \dd{r_1}
		= 2 \pi \int_0^1 \int_{2 - r_1}^{2 + r_1} \frac{r_1}{r_2^{1 + s}} \left(2\pi - 2 \arccos\left(\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2}\right) \right) \dd{r_2} \dd{r_1} \\
		 & = 4 \pi^2 \int_0^1 \int_{2 - r_1}^{2 + r_1} \frac{r_1}{r_2^{1 + s}} \dd{r_2} \dd{r_1} - 4 \pi \int_0^1 \int_{2 - r_1}^{2 + r_1} \frac{r_1}{r_2^{1 + s}} \arccos\left(\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2}\right) \dd{r_2} \dd{r_1},
		\intertext{then partial integration}
		 & = 4 \pi^2 \int_0^1 \int_{2 - r_1}^{2 + r_1} \frac{r_1}{r_2^{1 + s}} \dd{r_2} \dd{r_1} - \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{{(2 - r_1)}^s} \dd{r_1} + \frac{4\pi}{s} \int_0^1 \int_{2 - r_1}^{2 + r_2} \frac{r_1}{r_2^{1 + s}} \frac{r_2^2 - r_1^2 + 4}{\sqrt{4r_1^2 r_2^2 - {(r_1^2 + r_2^2 - 4)}^2}} \dd{r_2} \dd{r_1} \\
		 & = \underbrace{\frac{4\pi^2}{s(1 - s)(2 - s)} \left((s + 1) 3^{1 - s} - 2^{2 - s} \right)}_{- I_1} + \frac{4\pi}{s} \int_0^1 \int_{2 - r_1}^{2 + r_2} \frac{r_1}{r_2^{1 + s}} \frac{r_2^2 - r_1^2 + 4}{\sqrt{4r_1^2 r_2^2 - {(r_1^2 + r_2^2 - 4)}^2}} \dd{r_2} \dd{r_1}.
	\end{align*}

	Finally, we have for the second term in \Cref{eq:208}
	\begin{gather*}
		\L(E_0, E_1) = \frac{4\pi}{s} \int_0^1 \int_{2 - r_1}^{2 + r_2} \frac{r_1}{r_2^{1 + s}} \frac{r_2^2 - r_1^2 + 4}{\sqrt{4r_1^2 r_2^2 - {(r_1^2 + r_2^2 - 4)}^2}} \dd{r_2} \dd{r_1}.
	\end{gather*}

	We can now bound this term without losing too much information. For the upper bound, we will use
	that \( r_2 \geq 2 - r_1 \) and for the lower bound we will use that \( r_2 \leq 2 + r_1 \). We
	then get
	\begin{align*}
		\bullet) \quad \L(E_0, E_1)
		 & \leq \frac{4\pi}{s} \int_0^1 \int_{2 - r_1}^{2 + r_2} \frac{r_1}{{(2 - r_1)}^s} \frac{1}{r_2} \frac{r_2^2 - r_1^2 + 4}{\sqrt{4r_1^2 r_2^2 - {(r_1^2 + r_2^2 - 4)}^2}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4\pi}{s} \int_0^1 \frac{r_1}{{(2 - r_1)}^s} {\left[\arccos\left(\frac{r_1^2 + r_2^2 - 4}{2r_1 r_2}\right) \right]}_{2 - r_1}^{2 + r_2} \dd{r_1} \\
		% & = \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{{(2 - r_1)}^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1 - s)(2 - s)} \left(2^{2 - s} - 3 + s \right),
		\intertext{and}
		\bullet) \quad \L(E_0, E_1)
		 & \geq \frac{4\pi}{s} \int_0^1 \int_{2 - r_1}^{2 + r_2} \frac{r_1}{{(2 + r_1)}^s} \frac{1}{r_2} \frac{r_2^2 - r_1^2 + 4}{\sqrt{4r_1^2 r_2^2 - {(r_1^2 + r_2^2 - 4)}^2}} \dd{r_2} \dd{r_1} \\
		% & = \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{{(2 + r_1)}^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1 - s)(2 - s)} \left(2^{2 - s} - (s + 1) 3^{1 - s} \right).
	\end{align*}

	Thus, we have the bounds for \Cref{eq:208}
	\begin{gather*}
		\Per{s}{E_1}{} - 2\L(E_0, E_1) \leq \frac{2^{2 - s} \pi^{\frac{3}{2}}}{s(2 - s)} \frac{\Gamma (\frac{1 - s}{2})}{\Gamma (\frac{2 - s}{2})} - \frac{8\pi^2}{s(1 - s)(2 - s)} \left(2^{2 - s} - (s + 1) 3^{1 - s} \right), \tagged\label{eq:211}
	\end{gather*}
	and
	\begin{gather*}
		\Per{s}{E_1}{} - 2\L(E_0, E_1) \geq \frac{2^{2 - s} \pi^{\frac{3}{2}}}{s(2 - s)} \frac{\Gamma (\frac{1 - s}{2})}{\Gamma (\frac{2 - s}{2})} - \frac{8\pi^2}{s(1 - s)(2 - s)} \left(2^{2 - s} - 3 + s \right). \tagged\label{eq:212}
	\end{gather*}

	\begin{figure}[ht]
		\centering
		\def\svgscale{1}
		\import{figures/2D_bounds}{2D_bounded.pdf_tex}
		\caption{Upper and lower bound plotted for \( s \in (0, 1) \).}
		\label{fig:202}
	\end{figure}
\end{example}

\begin{example}[Continuation of \Cref{ex:201}]
	\label{ex:202}
	Let us now consider the same setting as in \Cref{ex:201}, but instead with the external data \(
	E_0 = B_{2 + T} \setminus B_2 \) for \( T > 0 \) large enough. Notice, that this change just adds
	one additional term compared to before
	\begin{gather*}
		\L(B_{2 + T}\setminus B_2, B_1) = \L(B_2^c, B_1) - \underbrace{\int_{B_{2 + T}^c} \int_{B_1} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{x} \dd{y}}_{I_3}
	\end{gather*}

	We will bound \( I_3 \) from above and below. \\
	The upper bound
	\begin{align*}
		\int_{B_1} \int_{B_{2 + T - \lvert x \rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{y} \dd{x}
		 & \leq 4 \pi^2 \int_0^1 \int_{2 + T - r_1}^\infty \frac{r_1}{r_2^{1 - s}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4 \pi^2}{s} \int_0^1 \frac{r_1}{{(2 + T - r_1)}^s} \dd{r_1} \\
		 & = \frac{4 \pi^2}{s(1 - s)(2 - s)} [{(2 + T)}^{2 - s} - (3 - s + T) {(1 + T)}^{1 - s}]
	\end{align*}
	and the lower bound
	\begin{align*}
		\int_{B_1} \int_{B_{2 + T + \lvert x \rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2 - s}} \dd{y} \dd{x}
		 & \geq 4 \pi^2 \int_0^1 \int_{2 + T + r_1}^{2 + T + r_1} \frac{r_1}{r_2^{1 - s}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4 \pi^2}{s} \int_0^1 \frac{r_1}{{(2 + T + r_1)}^s} \dd{r_1} \\
		 & = \frac{4 \pi^2}{s(1 - s)(2 - s)} [{(2 + T)}^{2 - s} - (1 + s + T) {(3 + T)}^{1 - s}].
	\end{align*}

	Thus, we have the bounds
	\begin{gather*}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega} \leq \Cref{eq:211} + \frac{8 \pi^2}{s(1 - s)(2 - s)} [{(2 + T)}^{2 - s} - (3 - s + T) {(1 + T)}^{1 - s}],
		\intertext{and}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega} \geq \Cref{eq:212} + \frac{8 \pi^2}{s(1 - s)(2 - s)} [{(2 + T)}^{2 - s} - (1 + s + T) {(3 + T)}^{1 - s}].
	\end{gather*}

	\begin{figure}[ht]
		\centering
		\def\svgscale{1}
		\import{figures/2D_bounds}{2D_unbounded.pdf_tex}
		\caption{Upper and lower bound plotted for \( s \in (0, 1) \) for \( T = 50000 \).}
		\label{fig:203}
	\end{figure}
\end{example}

We now want to generalize this example to arbitrary dimensions \( n\geq 2 \) and radii \( 0 < r < R
\). We will consider the following setting once with unbounded data and once with bounded data: Let
\( n \geq 2 \) and \( r, R, T > 0 \), such that \( r < R \). Take the external data \( E_0 = B_R^c
\) in the unbounded case and \( E_0 = B_{R + T} \setminus B_R \) in the bounded case and define the
prescribed set \( \Omega = B_r \). \\

In~\cite{Caffarelli2011} the authors have shown that for \( s \nearrow 1 \) the fractional perimeter
behaves like the classical perimeter. Thus, we can expect that for \( s \) large enough the minimizer
should be the external data itself. In~\cite{dipierro2012asymptotics} the authors have shown that
for bounded sets, say \( A \) and \( B \), the interaction multiplied with \( s \) goes to zero as
\( s \searrow 0 \), that is \( s \L(A, B) \to 0 \) as \( s \searrow 0 \), see~\cite[Eq. (3.2)]{dipierro2012asymptotics}.

\begin{theorem}
	\label{thm:201}
	Let \( n \geq 2 \) and \( 0 < r < R \). Let \( E_0 = B_R^c \) and \( \Omega = B_r \), then there
	exists an \( s_0 \in (0, 1) \) such that for all \( s \in (0, s_0) \) the minimizer is not the
	external data \( E_0 \) itself.
\end{theorem}

\begin{theorem}
	\label{thm:202}
	Let \( n \geq 2 \) and \( 0 < r < R \) and \( T > 0 \). Let \( E_0 = B_{R + T} \setminus B_R \)
	and \( \Omega = B_r \), then for any \( T \) large enough there exists \( s_0, s_1 \in (0, 1) \)
	such that for all \( s \in (s_0, s_1) \) the minimizer is not the external data \( E_0 \) itself.
\end{theorem}

\begin{proof}[Proof of \Cref{thm:201}]
	As in \Cref{ex:201} and \Cref{ex:202} we will compare the fractional perimeter of \( E_0 \cup
	\Omega \) relative to \( \Omega \) with the fractional perimeter of \( E_0 \) relative to \(
	\Omega \)

	\begin{gather*}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega} = \Per{s}{\Omega}{} -
		2\L(E_0, \Omega) = \Per{s}{B_r}{}- 2 \L(B_R^c, B_r). \tagged\label{eq:203}
	\end{gather*}

	For the first term we have by~\cite[Eq. (11)]{haddad2022affine}
	\begin{gather*}
		\Per{s}{B_r}{}
		= \frac{2^{1 - s} \pi^{\frac{n - 1}{2}} n \omega_n}{s(n - s)} \frac{\Gamma(\frac{1 - s}{2})}{\Gamma(\frac{n - s}{2})} r^{n - s}
		= \frac{2^{2 - s} \pi^{n - \frac{1}{2}}}{s(n - s)} \frac{\Gamma(\frac{1 - s}{2})}{\Gamma(\frac{n - s}{2}) \Gamma(\frac{n}{2})} r^{n - s}
	\end{gather*}
	with \( \omega_n = \frac{\pi^{\frac{n}{2}}}{\Gamma(\frac{n}{2} + 1)} \) and where \( \Gamma \) is the
	gamma function. \\

	The second term we will bound from below to get an upper bound for \Cref{eq:203}.
	\begin{align*}
		\L(B_r, B_R^c)
		 & = \int_{B_r} \int_{B_R^c} \frac{1}{\lvert x - y \rvert^{n - s}} \dd{y} \dd{x}
		\geq \int_{B_r} \int_{B_{R + \lvert x \rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{n + s}} \dd{y} \dd{x} \\
		 & = \int_{B_r} \int_{B_{R + \lvert x \rvert}^c} \frac{1}{\lvert y \rvert^{n + s}} \dd{y} \dd{x}
		= \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \int_0^r \int_{R + r_1}^\infty \frac{r_1^{n - 1}}{r_2^{1 + s}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{1}{s} \int_0^r \frac{r_1^{n - 1}}{{\left(R + r_1 \right)}^s} \dd{r_1} \\
		 & = \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{1}{ns} \frac{r^{n - 1}}{R^s} \HG\left(s, n ; n + 1 ; - \frac{r}{R}\right).
	\end{align*}

	In the last step we used the following identity~\cite{bateman_2023_cnd32-h9x80} for the hypergeometric
	function
	\begin{gather*}
		B(b, c - b)\HG(a, b ; c ; z) = \int_0^1 t^{b - 1} {(1 - t)}^{c - b - 1} {(1 - tz)}^{- a} \dd{t} \qquad
		\text{for}\ \Re(c) > \Re(b) > 0,
	\end{gather*}
	where \( B \) is the beta function. In our case we have \( a = s \), \( b = n \), \( c = n + 1 \)
	and \( z = - \frac{r}{R} \), thus
	\begin{align*}
		\int_0^r \frac{r_1^{n - 1}}{{\left(R + r_1 \right)}^s} \dd{r_1}
		 & = \frac{r^n}{R^s} \int_0^1 r_1^{n - 1} {(1 + \frac{r}{R} r_1)}^{- s} \dd{r_1} \\
		 & = \frac{r^n}{R^s} B(n, 1) \HG\left(s, n ; n + 1 ; - \frac{r}{R}\right) = \frac{r^n}{nR^s} \HG\left(s, n ; n + 1 ; - \frac{r}{R}\right).
	\end{align*}

	Thus, we can bound \Cref{eq:203} from above by
	\begin{align*}
		 & \Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega} \\
		 & \qquad \leq \frac{2^{2 - s} \pi^{n - \frac{1}{2}}}{s(n - s)} \frac{\Gamma(\frac{1 - s}{2})}{\Gamma(\frac{n - s}{2}) \Gamma(\frac{n}{2})}r^{n - s} - \frac{8 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{r^n}{snR^s} \HG\left(s, n ; n + 1 ; - \frac{r}{R}\right). \tagged\label{eq:204}
	\end{align*}

	Since we are interested in the behavior of \Cref{eq:203} depending on \( s \) we multiply
	\Cref{eq:204} by \( s(1 - s) \) to deal with the singularities at \( s = 0 \) and \( s = 1 \)
	\begin{align*}
		 & s(1 - s)(\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega}) \\
		 & \qquad \leq \frac{2^{3 - s} \pi^{n - \frac{1}{2}}}{n - s} \frac{\Gamma(\frac{3 - s}{2})}{\Gamma(\frac{n - s}{2}) \Gamma(\frac{n}{2})}r^{n - s} - \frac{8 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{r^n}{nR^s} (1 - s)\HG\left(s, n ; n + 1 ; - \frac{r}{R}\right). \tagged\label{eq:205}
	\end{align*}

	Since \( \Gamma \) is continuous for all positive reals and \( \HG \) is absolutely continuous for
	\( \lvert z \rvert < 1 \)~\cite{bateman_2023_cnd32-h9x80}, the right-hand side of \Cref{eq:205} is continuous for all \( s \in
	(0, 1) \). First notice that we have the following limits
	\begin{align*}
		\lim_{s \searrow 0} \HG(s, n ; n + 1 ; z) = 1 \quad \text{and} \quad \lim_{s \nearrow 1} (1-s)\HG(s, n ; n + 1 ; z) = 0,
	\end{align*}
	since for \( \lvert z \rvert < 1 \) the hypergeometric function has the following expression
	\begin{gather*}
		\HG(a, b ; c ; z) = \sum_{k = 0}^\infty \frac{{(a)}_k {(b)}_k}{{(c)}_k} \frac{z^k}{k!},
	\end{gather*}
	for \( {(q)}_k = q(q + 1)\ldots(q + k-1) \) and \( {(q)}_0 = 1 \) whenever \( q > 0 \).

	Now take the limit for \( s \searrow 0 \) and \( s \nearrow 1 \) in \Cref{eq:205}
	\begin{gather*}
		\lim_{s \searrow 0} s(1 - s)(\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega})
		= - \frac{4 \pi^n}{n} \frac{1}{{(\Gamma(\frac{n}{2}))}^2} r^n < 0
	\end{gather*}
	and
	\begin{gather*}
		\lim_{s \nearrow 1} s(1 - s)(\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega})
		= \frac{4 \pi^{n - \frac{1}{2}}}{n - 1} \frac{1}{\Gamma(\frac{n - 1}{2})\Gamma(\frac{n}{2})} r^{n - 1} > 0. \tagged\label{eq:206}
	\end{gather*}

	Now we know for \( s \nearrow 1 \) that \( (1 - s)\Per{s}{E}{\Omega} \) is approaching the
	classical perimeter whenever the classical perimeter is finite, thus in \Cref{eq:206} is actually
	an equality. Thus, we can conclude that there exists an \( s_0 \in (0, 1) \) such that for all \(
	s \in (0, s_0) \) the minimizer is not the external data itself.

\end{proof}


\begin{proof}[Proof of \Cref{thm:202}]
	We consider again the difference
	\begin{align*}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega}
		 & = \Per{s}{\Omega}{} - 2\L(E_0, \Omega) \\
		 & = \Per{s}{B_r}{} - 2 \L(B_R^c, B_r) + 2 \L(B_{R + T}^c, B_r). \tagged\label{eq:209}
	\end{align*}

	We can use the upper bound from the proof of \Cref{thm:201} for the first 2 terms in
	\Cref{eq:209}. The third term we will bound from above
	\begin{align*}
		\L(B_{R + T}^c, B_r)
		 & = \int_{B_r} \int_{B_{R + T}^c} \frac{1}{\lvert x - y \rvert^{n - s}} \dd{y} \dd{x}
		\leq \int_{B_r} \int_{B_{R + T - \lvert x \rvert}^c} \frac{1}{\lvert x - y \rvert^{n - s}} \dd{y} \dd{x} \\
		 & = \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \int_0^r \int_{R + T - r_1}^\infty \frac{r_1^{n - 1}}{r_2^{1 + s}} \dd{r_2} \dd{r_1}
		= \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{1}{s} \int_0^r \frac{r_1^{n - 1}}{{(R + T - r_1)}^s} \dd{r_1} \\
		 & = \frac{4 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{1}{ns} \frac{r^n}{{(R + T)}^s} \HG\left(s, n ; n + 1 ; - \frac{r}{R + T}\right).
	\end{align*}

	Thus, we can bound \Cref{eq:209} from above by
	\begin{gather*}
		\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega}
		\leq \Cref{eq:204} + \frac{8 \pi^n}{{(\Gamma(\frac{n}{2}))}^2} \frac{1}{ns} \frac{r^n}{{(R + T)}^s} \HG\left(s, n ; n + 1 ; - \frac{r}{R + T}\right) \tagged\label{eq:210}
	\end{gather*}

	Now we multiply by \( s(1 - s) \) again to deal with the singularities at \( s = 0 \), \( s = 1 \)
	and take the limits
	\begin{gather*}
		\lim_{s \searrow 0} s(1 - s)(\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega}) = \frac{4 \pi^n}{n} \frac{1}{{(\Gamma(\frac{n}{2}))}^2} r^n > 0,
	\end{gather*}
	and
	\begin{gather*}
		\lim_{s \nearrow 1} s(1 - s)(\Per{s}{E_0 \cup \Omega}{\Omega} - \Per{s}{E_0}{\Omega}) = \frac{4 \pi^{n - \frac{1}{2}}}{n - 1} \frac{1}{\Gamma(\frac{n - 1}{2})\Gamma(\frac{n}{2})} r^{n - 1} > 0.
	\end{gather*}

	Notice, that the limits are independent of \( R \) and \( T \). Also, both limits are positive.
	Nonetheless, for \( T \) big enough, there will exist some interval in \( (0, 1) \) such that the
	difference is negative. \\

	The upper bound \Cref{eq:210} is continuous in \( T \) for all \( s \in (0, 1) \) and for \( T \to
	\infty \) the third term vanishes. Thus, the upper bound converges pointwise to the upper bound in
	the proof of \Cref{thm:201}. Thus, for \( T \) big enough there exists some \( s \in (0, 1) \) such
	that the difference is negative. \\

	The limit for \( s \searrow 0 \) is independent of \( T \), positive and by~\cite[Eq.
		(3.2)]{dipierro2012asymptotics} we have that \( s \L(B_{R + T}\setminus B_R, B_r) \to 0 \) for \(
	s \searrow 0 \), thus the limits in \( s = 0 \) and \( s = 1 \) are not only upper bounds but
	exact values. \\

	Thus, we can conclude, that there exists an interval \( (s_0, s_1) \) such that for all \( s \in
	(s_0, s_1) \) the minimizer is not the external data itself.

\end{proof}

When comparing both theorems and their proofs, we notice that the example with bounded external
data doesn't seem to converge to the example of unbounded external data, at least in the limit for
\( s \searrow 0 \). This is interesting, as this entails, that if we want to analyze the limiting
behavior of a minimizer for \( s \searrow 0 \) we cannot restrict the boundary data to be bounded or
unbounded as the behavior might be different. \\

In conclusion, if we are in the setting of having external data \( E_0 \) and prescribed set \(
\Omega \) with nonzero distance, then we cannot assume the minimizer to be the external data.
Whereas for classical minimal surfaces we can do that, nonlocal minimal surfaces can generate mass
completely disconnected from its external data. Since for \( s \nearrow 1 \) the fractional
perimeter behaves like the classical perimeter, we can at least say that for \( s \) close to 1 the
minimizer will be the external data. Additionally, if we have bounded set \( E_0 \) and \( \Omega \)
then by the work of the authors of~\cite{dipierro2012asymptotics} we can conclude the same. However,
for general \( s \in (0, 1) \) we cannot do the same. \\

Nonetheless, we suspect that for \( E_0 \) and \( \Omega \) with zero distance, that there exists no
connected component \( E_1 \) part of the minimizer such that \( E_1 \) has nonzero distance from \(
E_0 \). This conjecture is based on the idea, that for two sets of the same size, the one connected
to either \( E_0 \) or \( \Omega \) will expose less surface area than the one connected to neither
and thus will have a smaller fractional perimeter relative to \( \Omega \).
