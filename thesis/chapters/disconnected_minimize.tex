% Touching sets
\chapter{Disconnected Minimizer}
\label{ch:disconnected_minimizer}

\begin{TODO}
	Maybe focus more on the model in \( \mathbb{R}^2 \) and balls\\
	0. Show that for \( E_0 = B_2^c \) and \( E_1 = B_1 \) the minimizer is not \( E_0 \)
	itself for small \( s \) \\
	1. Extend to \( r \) and \( R \) (Should work as well)\\
	2. Take \( E_0 \) bounded (strange behavior, as \( s \to 0^+ \))\\
	3. Extend to arbitrary \( E_0 \subset B_R^c \) and \( E_1 \subset B_r \) \\
	4. What about disconnected \( \Omega \)
\end{TODO}

Example of a minimizer that has a non-empty set in \( \Omega \), while \( d(E_0, \Omega)
\eqqcolon d > 0 \).\newline
Compare to classical case, where this cannot happen. Refer to.. and.. where discussion
about the behavior of the perimeter for \( s \to 1^- \) and \( s \to 0^+ \) was done.
\newline
Connect to the discussion in \cref{sec:model02}..\newline
Add discussion why \( n = 1 \) doesn't make sense or has a special standing.\newline

Idea: If \( d(E_0, \Omega) = 0 \), does there exist a connected component \( F \subset E
\) s.t.\ \( d(E_0, F) > 0 \)?\newline

In \Cref{sec:model02} we discussed the behavior of the perimeter for external data with
varying height \( R \). We found that the minimizer of \( E_M \) contains the cylinder \(
B^\prime_{\frac{R}{2}} \times [-M, M] \) for \( R < 2 \). A natural question to follow is
whether the minimizer, which connects the external data, is in fact connected. A priori we
don't know if there exists a part of the minimizer that is disconnected from the
cylinder.\newline

Intuitively, we would expect that the minimizer is connected, since
\begin{TODO}
	Add an intuitive argument about volume increase and surface increase.
\end{TODO}

In an effort to prove that, we first looked at a model with \( \dist(E_0, \Omega) > 0 \)
for some \( E_0, \Omega \in \mathbb{R}^n \). From the classical case we know that in this
case the minimizer is the external data \( E_0 \) itself already. If this holds in the
nonlocal setting as well, then we could conclude that the minimizer in \Cref{thm:103} has
to be connected.

Let \( Z_R \coloneqq \{(x^\prime, x_n) \in \mathbb{R}^{n-1} \times \mathbb{R} \mid \lvert
x^\prime \rvert < \frac{R}{2}, \lvert x_n \rvert < M \} \) be the cylinder, then \( Z_2 \)
is the cylinder from \Cref{sec:model02}. We define the set \( \Omega_1 \coloneqq Z_2
\setminus Z_R \) and \( E_1 \coloneqq \Omega_1 \cap E_M \) to be the set of the minimizer
\( E_M \) in \Cref{thm:103} that is outside of the cylinder \( Z_R \) for \( R < 2 \). We
then rewrite the nonlocal Perimeter of \( E_M \) reltaive to \( \Omega \) as
\begin{align}
	\Per{s}{E_M}{\Omega}
	 & = \L(E_M \cap \Omega, E_M^c) + \L(E_M \setminus \Omega, \Omega \setminus E_M) \\
	 & = \L(Z_R \cup E_1, E_M^c) + \L(E_0, \Omega \setminus E_1) \\
	 & = \L(E_1, E_M^c) + \L(E_0, \Omega \setminus E_1) + \L(Z_R, E_M^c) \\
	 & = \Per{s}{E_M}{\Omega_1} + \L(Z_R, (E_0 \cup \Omega)^c). \label{eq:201}
\end{align}
\begin{TODO}
	Check the computations
\end{TODO}
Notice that the second term in \Cref{eq:201} is independent of \( E_1 \), thus to minimize
\( \Per{s}{E_M}{\Omega} \), we can minimize \( \Per{s}{E_M}{\Omega_1} \) instead. Now
assume that \( E_1 \) is disconnected from \( E_0 \cup Z_R \), then for any \( \delta > 0
\), define \( \Omega_{1, \delta}\coloneqq \{x \in \Omega \mid d(x, \Omega^c) > \delta \}
\). Then we notice that
\begin{gather}
	\Omega_{1, \delta} \nearrow \Omega_1 \text{in..} \\
	\Per{s}{E_M}{\Omega_{1, \delta}} \nearrow \Per{s}{E_M}{\Omega_1} \\
	\dist(E_0, \Omega_{1, \delta}) > 0 \text{ for all~} \delta > 0 \\
\end{gather}
\begin{TODO}
	Justify those limits
\end{TODO}
Thus we are in the setting of the classical case, we could conclude that the minimizer
should be connected. \\
However in the nonlocal setting, we can observe a new behavior. As mentioned before, in
the classical case, if the external data and the prescribed set are disconnected,
\begin{TODO}
	Disconnected in what sense?\\
	Elaborate, why is that Interesting
\end{TODO}
then the minimizer is the external data itself. In the following we will give an example
of a model, whose minimizer is not the external data itself, but contains a non-empty set
in the prescribed set. This however depends on \( s \), since for \( s \to 1^- \) the
nonlocal perimeter converges to the classical perimeter in some sense.
\begin{TODO}
	Convergence in what sense?\\
	Sources
\end{TODO}

First, we will see that in \( n = 1 \) the nonlocal minimizer behaves like the classical
minimizer, which showcases another example, that \( n = 1 \) doesn't make sense.. or has a
special standing. \newline
Then we will give an example of a model, whose minimizer is not the external data itself.


\section{Unbounded external data}
\label{sec:unbounded_external_data}

\begin{TODO}
	Rewrite with choice of \( \Omega \) and \( E_1 \) in mind
\end{TODO}

Consider the following model in \( \mathbb{R}^2 \):\\
Let \( E_0 \coloneqq B_2^c \) and \( \Omega \coloneqq B_1 \). Then we show that there
exists \( s_0 \in (0, 1) \) such that for all \( s \in (0, s_0) \) the minimizer \( E \)
is not the external data \( E_0 \) itself. We do that by showing that for those \( s \)
the fractional perimeter of \( E_0 \) relative to \( \Omega \) is strictly smaller than
the fractional perimeter of \( E_0 \cap E_1 \) relative to \( \Omega \) with \( E_1 = B_1
\).
\begin{TODO}
	Improve proof and figure
\end{TODO}

\begin{proof}
	We compare \( \Per{s}{E_0 \cup E_1}{\Omega} \) with \( \Per{s}{E_0}{\Omega} \).
	\begin{align}
		\Per{s}{E_0 \cup E_1}{\Omega} - \Per{s}{E_0}{\Omega}
		 & = \L(E_1, (E_0 \cup E_1)^c) + \L(E_0, \Omega \setminus E_1) - \L(E_0, \Omega) \\
		 & = \L(E_1, E_1^c) - 2 \L(E_0, E_1) \\
		 & = \Per{s}{E_1}{} - 2 \L(E_0, E_1). \label{eq:202}
	\end{align}
	We can give an explicit value for the first term in \Cref{eq:202} by using the result
	of~\cite[Eq. (11)]{haddad2022affine}. We then have
	\begin{gather}
		\Per{s}{E_1}{} = \frac{2^{2-s} \pi^{\frac{3}{2}}}{s(2-s)} \frac{\Gamma (\frac{1-s}{2})}{\Gamma (\frac{2-s}{2})},
	\end{gather}
	where \( \Gamma \) is the gamma function. The second term in \Cref{eq:202} is not so
	easy to compute, thus we will estimate it from above and below. Since these are rather
	delicate computations, we have to refine the integral first. To do that we split the
	domain of integration over the second variable into two parts depended on the first,
	namely \( B_{2+\lvert x\rvert}^c (x) \) and \( B_{2+\lvert x\rvert} (x) \setminus B_2
	\) for \( x \in B_1 = E_1 \). We then can write the second term as
	\begin{gather}
		\L(E_0, E_1) = \underbrace{\int_{B_1} \int_{B_{2+\lvert x\rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2+s}} \dd{y} \dd{x}}_{\eqqcolon I_1} + \underbrace{\int_{B_1} \int_{B_{2+\lvert x\rvert} (x) \setminus B_2} \frac{1}{\lvert x - y \rvert^{2+s}} \dd{y} \dd{x}}_{\eqqcolon I_2}.
	\end{gather}
	See \Cref{fig:201} for splitup \\
	\begin{figure}[h]
		\centering
		\def\svgwidth{0.5\textwidth}
		\import{figures/split_domain}{split_domain.pdf_tex}
		\caption{SplitUp of Domain}
		\label{fig:201}
	\end{figure}
	We start with \( I_1 \):
	\begin{align}
		I_1
		 & = \int_{B_1} \int_{B_{2+\lvert x\rvert}^c (x)} \frac{1}{\lvert x - y \rvert^{2+s}} \dd{y} \dd{x} \\
		 & = \int_{B_1} \int_{B_{2+\lvert x\rvert}^c} \frac{1}{\lvert y \rvert^{2+s}} \dd{y} \dd{x} \\
		 & = 4 \pi^2 \int_0^1 \int_{2+r_1}^\infty \frac{r_1}{r_2^{1+s}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \int_0^1 \left[ -\frac{r_1}{r_2^s} \right]_{2+r_1}^\infty \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{(2+r_1)^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \int_2^3 \frac{r_1 -2}{r_1^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \left[ \frac{r_1^{2-s}}{2-s} - 2 \frac{r_1^{1-s}}{1-s} \right]_2^3 \\
		 & = \frac{4\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -(s+1) 3^{1-s} \right).
	\end{align}
	Thus for \( I_1 \) we have
	\begin{gather}
		I_1 = \frac{4\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -(s+1) 3^{1-s} \right). \label{eq:203}
	\end{gather}
	Now to \( I_2 \). Here the idea is to use radial coordinates again. Since the ntegral
	is radial symmetric with respect to \( x \), we can fix \( x \) such that \( x = (r,
	0) \) for \( r = \lvert x\rvert \). Now for fixed \( x \) the domain of \( y \) is not
	radial symmetric anymore, thus we first have to compute the domain of \( \vartheta:=
	\vartheta (r_1, r_2) \). \\
	We have two restrictions on \( y \):
	\begin{TODO}
		Give justifications of bounds
	\end{TODO}
	\begin{enumerate}[label = (\arabic*)]
		\item \( 4 \leq \lvert x-y\rvert^2 \leq (2+2\lvert x\rvert)^2 \)
		\item \( 2-\lvert x\rvert \leq \lvert y\rvert \leq 2+\lvert x\rvert \)
	\end{enumerate}
	From the first restriction with \( \lvert x\rvert = r_1 \), \( \lvert y\rvert = r_2 \)
	and \( \vartheta \) the angle between \( x \) and \( y \) we get
	\begin{gather}
		4 \leq \lvert x-y\rvert^2 \leq (2+2r_1)^2 \\
		\Leftrightarrow 4 \leq r_1^2 + r_2^2 - 2r_1 r_2 \cos(\vartheta) \leq 4(1+r_1)^2 \\
		\Leftrightarrow \frac{r_1^2+r_2^2-4}{2r_1 r_2} \geq \cos(\vartheta) \geq \frac{r_1^2+r_2^2-4(1+r_1)^2}{2r_1 r_2}. \label{eq:204}
	\end{gather}
	From the second restriction we get that the right-hand-side of \Cref{eq:204} is always
	greater or equal to \( -1 \), thus we have
	\begin{gather}
		\frac{r_1^2+r_2^2-4}{2r_1 r_2} \geq \cos(\vartheta) \geq -1.
	\end{gather}
	We will see, that for all \( r_1 \) and \( r_2 \) the argument is independent of \(
	\vartheta \), thus we can integrate over \( \vartheta \) first. We then get
	\begin{TODO}
		Argument for symmetry and how domain was chosen
	\end{TODO}
	\begin{gather}
		\int_{-\vartheta}^\vartheta \dd{\vartheta} = 2\pi - 2 \arccos\left(\frac{r_1^2+r_2^2-4}{2r_1 r_2}\right).
	\end{gather}
	For \( I_2 \) we get then
	\begin{TODO}
		Simplify computations?\\
		Add arguments about splitting, change of variables, computationsteps etc
	\end{TODO}
	\begin{align}
		I_2
		 & = \int_{B_1} \int_{B_{2+\lvert x\rvert} (x) \setminus B_2} \frac{1}{\lvert x - y \rvert^{2+s}} \dd{y} \dd{x} \\
		 & = \int_{B_1} \underbrace{\int_{B_{2+\lvert x\rvert} \setminus B_2(-x)} \frac{1}{\lvert y \rvert^{2+s}} \dd{y}}_{\text{radial symmetric w.r.t.\ \( x \)}} \dd{x} \\
		 & = 2 \pi \int_0^1 \int_{2-r_1}^{2+r_1} \frac{r_1}{r_2^{1+s}} \int_{-\vartheta}^\vartheta \dd{\vartheta} \dd{r_2} \dd{r_1} \\
		 & = 2 \pi \int_0^1 \int_{2-r_1}^{2+r_1} \frac{r_1}{r_2^{1+s}} \left( 2\pi -2 \arccos\left(\frac{r_1^2+r_2^2-4}{2r_1 r_2}\right) \right) \dd{r_2} \dd{r_1} \\
		 & = 4 \pi^2 \int_0^1 \int_{2-r_1}^{2+r_1} \frac{r_1}{r_2^{1+s}} \dd{r_2} \dd{r_1} - 4 \pi \int_0^1 \int_{2-r_1}^{2+r_1} \frac{r_1}{r_2^{1+s}} \arccos\left(\frac{r_1^2+r_2^2-4}{2r_1 r_2}\right) \dd{r_2} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1-s)(2-s)} \left( (s+1) 3^{1-s}-3+s \right) - \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{(2-r_1)^s} \dd{r_1} + \frac{4\pi}{s} \int_0^1 \int_{2-r_1}^{2+r_2} \frac{r_1}{r_2^{1+s}} \frac{r_2^2 -r_1^2 +4}{\sqrt{4r_1^2 r_2^2 - (r_1^2 +r_2^2 -4)^2}} \dd{r_2} \dd{r_1} \\
		 & = \underbrace{\frac{4\pi^2}{s(1-s)(2-s)} \left((s+1) 3^{1-s} - 2^{2-s} \right)}_{-I_1} + \frac{4\pi}{s} \int_0^1 \int_{2-r_1}^{2+r_2} \frac{r_1}{r_2^{1+s}} \frac{r_2^2 -r_1^2 +4}{\sqrt{4r_1^2 r_2^2 - (r_1^2 +r_2^2 -4)^2}} \dd{r_2} \dd{r_1}.
	\end{align}
	Thus we get for the second term in \Cref{eq:202}
	\begin{gather}
		\L(E_0, E_1) = \frac{4\pi}{s} \int_0^1 \int_{2-r_1}^{2+r_2} \frac{r_1}{r_2^{1+s}} \frac{r_2^2 -r_1^2 +4}{\sqrt{4r_1^2 r_2^2 - (r_1^2 +r_2^2 -4)^2}} \dd{r_2} \dd{r_1}.
	\end{gather}
	We can now bound this term without losing too much information. For the upper bound,
	we will use that \( r_2 \geq 2-r_1 \) and for the lower bound we will use that \( r_2
	\leq 2+r_1 \). We then get
	\begin{align}
		\bullet) \quad \L(E_0, E_1)
		 & \leq \frac{4\pi}{s} \int_0^1 \int_{2-r_1}^{2+r_2} \frac{r_1}{(2-r_1)^s} \frac{1}{r_2} \frac{r_2^2 -r_1^2 +4}{\sqrt{4r_1^2 r_2^2 - (r_1^2 +r_2^2 -4)^2}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4\pi}{s} \int_0^1 \frac{r_1}{(2-r_1)^s} \left[ \arccos\left(\frac{r_1^2+r_2^2-4}{2r_1 r_2}\right) \right]_{2-r_1}^{2+r_2} \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{(2-r_1)^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -3+s \right)
		\intertext{and}
		\bullet) \quad \L(E_0, E_1)
		 & \geq \frac{4\pi}{s} \int_0^1 \int_{2-r_1}^{2+r_2} \frac{r_1}{(2+r_1)^s} \frac{1}{r_2} \frac{r_2^2 -r_1^2 +4}{\sqrt{4r_1^2 r_2^2 - (r_1^2 +r_2^2 -4)^2}} \dd{r_2} \dd{r_1} \\
		 & = \frac{4\pi^2}{s} \int_0^1 \frac{r_1}{(2+r_1)^s} \dd{r_1} \\
		 & = \frac{4\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -(s+1) 3^{1-s} \right).
	\end{align}
	Thus we have that
	\begin{gather}
		\frac{2^{2-s} \pi^{\frac{3}{2}}}{s(2-s)} \frac{\Gamma (\frac{1-s}{2})}{\Gamma (\frac{2-s}{2})} - \frac{8\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -3+s \right)
		\leq \Per{s}{E_1}{} -2\L(E_0, E_1)
		\leq \frac{2^{2-s} \pi^{\frac{3}{2}}}{s(2-s)} \frac{\Gamma (\frac{1-s}{2})}{\Gamma (\frac{2-s}{2})} - \frac{8\pi^2}{s(1-s)(2-s)} \left( 2^{2-s} -(s+1) 3^{1-s} \right)
	\end{gather}
	\begin{TODO}
		Give justification, that both sides are continuous w.r.t.\ s and conclude\\
		Maybe draw a picture
	\end{TODO}
\end{proof}

\begin{TODO}
	Add conclusion for \Cref{sec:model02} Minimizer could still be connected as mentioned
	in the intuitive approach.
\end{TODO}

\section{Bounded external data}
\label{sec:bounded_external_data}

\begin{TODO}
	Show that for \( E_0 \) bounded, the minimizer is connected for \( s \) small and
	large enough (at least in the model above)
\end{TODO}

\begin{TODO}
	Is that interesting?\\
	Show it doesn't even work for \( n = 1 \), but add discussion whether \( n = 1 \)
	makes even sense to consider
\end{TODO}